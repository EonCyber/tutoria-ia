#genai #langgraph #langchain #agentes #aula #mentoriafire 

## 1. ğŸŒ‰ DiferenÃ§a entre LLM Applications (non-agentic) e Agentic LLM Applications

### LLM Application (com Chain, Prompt ou Tool Calling)

- **DeterminÃ­stica / Linear**: recebe um input, processa via um fluxo previsÃ­vel (ex: prompt â†’ LLM â†’ output).
    
- **Chains**: modelam sequÃªncias de passos (ex: perguntar â†’ buscar documento â†’ responder).
    
- **Tool Calling**: LLM chama funÃ§Ãµes externas sob demanda, com base no input.
    

### Agentes com LLM

- **Autonomia e raciocÃ­nio iterativo**: nÃ£o seguem um fluxo fixo, e sim _decidem_ o que fazer com base no estado atual.
    
- **Tomam decisÃµes**: escolhem ferramentas, reavaliam contexto, planejam passos futuros.
    
- **TÃªm memÃ³ria e objetivo**: recebem uma _tarefa_ e a perseguem atÃ© completar.
    

ğŸ” **Exemplo claro**:

- Uma chain pode responder â€œqual a capital da FranÃ§a?â€ com um lookup.
    
- Um agente pode receber â€œorganize minha agenda da semanaâ€ e interagir com mÃºltiplas ferramentas e decisÃµes atÃ© concluir a tarefa.

#### ğŸ’° **Custo e uso de tokens em Agentes vs AplicaÃ§Ãµes nÃ£o Agenticas**
### âš–ï¸ Comparativo geral:

| Aspecto                       | LLM Tradicional (nÃ£o agente)      | LLM Agent (com raciocÃ­nio e aÃ§Ãµes)               |
| ----------------------------- | --------------------------------- | ------------------------------------------------ |
| ğŸ§¾ **Chamadas ao modelo**     | 1 ou poucas por interaÃ§Ã£o         | MÃºltiplas chamadas por tarefa                    |
| ğŸ§  **Tokens de entrada**      | Prompt direto + contexto limitado | Prompt + histÃ³rico de raciocÃ­nio + state         |
| ğŸ“¤ **Tokens de saÃ­da**        | Apenas resposta final             | VÃ¡rias respostas intermediÃ¡rias + logs           |
| ğŸ” **IteraÃ§Ãµes**              | Normalmente uma                   | 3, 5, 10+ por tarefa, dependendo da complexidade |
| âš™ï¸ **Ferramentas externas**   | Raras ou manuais                  | Invocadas frequentemente pelo agente             |
| ğŸ’¸ **Custo final (estimado)** | Baixo e previsÃ­vel                | Mais alto e variÃ¡vel (depende da lÃ³gica)         |
ğŸ“Œ **Por que agentes consomem mais tokens?**

- **Loop de raciocÃ­nio (ReAct)**:
    
    - Cada pensamento + aÃ§Ã£o + observaÃ§Ã£o Ã© uma nova chamada.
        
    - Ex: "Pensando" â†’ "AÃ§Ã£o: Buscar" â†’ "ObservaÃ§Ã£o: Resultado" â†’ repete...
        
- **Prompt mais longo**:
    
    - Para cada passo, o prompt inclui histÃ³rico de aÃ§Ãµes anteriores.
        
    - Muitas vezes hÃ¡ uma "memÃ³ria" temporÃ¡ria com o state completo.
        
- **Tomada de decisÃ£o explÃ­cita**:
    
    - O LLM precisa ser instruÃ­do a escolher entre ferramentas, avaliar condiÃ§Ãµes, ou decidir prÃ³ximo passo â€” o que exige mais contexto no input.
#### âœ… AplicaÃ§Ã£o tradicional:

- Prompt: 500 tokens
    
- Resposta: 300 tokens  
    **Total: ~800 tokens por tarefa**
    

#### ğŸ¤– Agente com 5 ciclos ReAct:

- Prompt inicial: 700 tokens (com ferramentas + instruÃ§Ãµes)
    
- 5 passos com raciocÃ­nio/aÃ§Ã£o/observaÃ§Ã£o:
    
    - Cada loop: 400~700 tokens
        
- Total: ~3000â€“5000 tokens por tarefa
    

> **Resultado:** Agentes podem custar **4x a 10x mais tokens** por tarefa comparado a chamadas diretas.

### âš ï¸ **Quando isso vale a pena?**

- Quando a **tarefa Ã© complexa**, multietapas ou exige **autonomia**.
    
- Quando o custo humano de intervenÃ§Ã£o seria mais caro.
    
- Quando **flexibilidade e escalabilidade** sÃ£o prioridade (ex: copilots, automaÃ§Ãµes, assistentes).
    

---

### ğŸ’¡ **Boas prÃ¡ticas para reduzir custo de agentes**

- Limitar profundidade de ciclos (`max_iterations` no LangGraph).
    
- Usar `cache` em ferramentas e LLMs.
    
- Minimizar quantidade de tokens no state/contexto.
    
- Criar _short-term memory compression_ (resumir histÃ³rico).
    
- Escolher modelos menores onde possÃ­vel (ex: GPT-3.5 para raciocÃ­nio leve, GPT-4 para etapas crÃ­ticas).

## 2. ğŸ¤– Algoritmos de Agentes de LLM
### 2.1. ReAct (Reason + Act)

- ğŸ“š Paper: _ReAct: Synergizing Reasoning and Acting in Language Models_
    
- ğŸ§  LLM alterna entre _pensar_ (reasoning) e _agir_ (fazer chamadas de ferramentas).
    
- Exemplo:
    
    - Thought: "Preciso buscar os eventos da agenda"
        
    - Action: `get_calendar_events()`
        

âœ… Vantagens: eficaz para tarefas com raciocÃ­nio lÃ³gico e mÃºltiplas etapas.  
âš ï¸ Desafio: sem memÃ³ria de longo prazo nativa.

---
### 2.2. Plan & Execute (Planner + Executor)

- ğŸ“… Divide o problema em duas fases:
    
    - **Planner**: cria um plano de alto nÃ­vel.
        
    - **Executor**: executa cada etapa do plano com raciocÃ­nio local.
        
- Bom para tarefas longas e complexas (ex: planejamento de viagem, pipelines).
    

âœ… Vantagens: maior controle e previsibilidade.  
âš ï¸ Mais complexo de implementar.

---
### 2.3. Conversational Agent

- ğŸ—£ï¸ MantÃ©m um diÃ¡logo com o usuÃ¡rio, decide aÃ§Ãµes com base no histÃ³rico.
    
- Usa memÃ³ria conversacional, tracking de contexto e decisÃµes.
    

âœ… Vantagens: Ã³timo para chatbots e assistentes.  
âš ï¸ LimitaÃ§Ã£o em tarefas com mÃºltiplos objetivos simultÃ¢neos.

--- 
### 2.4. AutoGPT-style Agents (Loop autÃ´nomo)

- ğŸ” O LLM define o objetivo, pensa, age, reflete e repete o ciclo atÃ© o objetivo ser alcanÃ§ado.
    
- Integra raciocÃ­nio, ferramentas e criticidade.
    

âœ… Poderosos para exploraÃ§Ã£o aberta.  
âš ï¸ Dificuldade de controle, alto custo computacional.

--- 
### 2.5. Outros Modelos Relevantes

- **Reflexion**: LLM avalia suas prÃ³prias aÃ§Ãµes, ajustando o comportamento.
    
- **Toolformer**: LLM aprende _quando_ usar ferramentas a partir do treinamento supervisionado.

## 3. ğŸ§  Multi-Agent Systems e Swarms

### O que Ã© um sistema multiagente?

- Uma arquitetura onde **vÃ¡rios agentes** cooperam, competem ou se comunicam para atingir objetivos.
    
- Cada agente pode ter:
    
    - Um papel distinto (planner, executor, comunicador).
        
    - Autonomia parcial.
        
    - Um objetivo local e/ou global.
        

### Como funciona?

- Pode usar:
    
    - **CoordenaÃ§Ã£o direta**: mensagens entre agentes.
        
    - **Ambientes compartilhados**: ex: blackboards, memÃ³ria comum.
        
- EstratÃ©gias de orquestraÃ§Ã£o:
    
    - HierÃ¡rquica (um agente lÃ­der)
        
    - HeterÃ¡rquica (todos iguais)
        
    - Swarm (inspirado em colÃ´nias de insetos)
        

### Para que pode ser usado?

- ğŸ‘· DevOps (ex: um swarm para deploy)
    
- ğŸ“… OrganizaÃ§Ã£o pessoal (um agente para agenda, outro para e-mails, outro para tarefas)
    
- ğŸ”¬ Pesquisa e raciocÃ­nio colaborativo (multiagentes debatendo soluÃ§Ãµes)
    
- ğŸ§¬ SimulaÃ§Ã£o de comportamento coletivo (IA social, jogos, IoT)

## 4. âš™ï¸ IntroduÃ§Ã£o ao LangGraph

### O que Ã© o LangGraph?

- Um _motor de agentes baseado em grafos de estado_.
    
- Foi criado para dar **controle, seguranÃ§a e auditabilidade** na execuÃ§Ã£o de agentes.
    
- Inspirado em grafos de automatos finitos.
    

### Componentes principais:

1. **StateGraph**: define os nÃ³s e transiÃ§Ãµes possÃ­veis.
    
2. **States**: representam a memÃ³ria e estado da execuÃ§Ã£o.
    
3. **Edges (TransiÃ§Ãµes)**: controlam o fluxo, com lÃ³gica condicional.
    
4. **Node Functions**: aÃ§Ãµes executadas em cada estado.
    
5. **Checkpoints**: permitem retomar, debugar, versionar execuÃ§Ãµes.
    
6. **LangGraph Studio**: interface de visualizaÃ§Ã£o do fluxo em tempo real.
    

### BenefÃ­cios:

- ğŸ’¡ FÃ¡cil visualizaÃ§Ã£o do fluxo do agente.
    
- ğŸ” Previsibilidade e testes.
    
- ğŸ” Suporte a loops, branches e paralelismo.
    
- ğŸ§  Perfeito para construir sistemas multiagentes e controlÃ¡veis.


###  Apoio

ğŸ“Œ Tipos Comuns de Nodes:

| Tipo de Node | FunÃ§Ã£o tÃ­pica                               | Exemplo                            |
| ------------ | ------------------------------------------- | ---------------------------------- |
| `llm`        | Chamadas a LLM para decidir ou gerar saÃ­das | "Decida qual ferramenta usar"      |
| `tool`       | Chamada a ferramenta externa                | `get_events_from_calendar()`       |
| `router`     | Direciona o fluxo com base em condiÃ§Ãµes     | "Se for erro, vÃ¡ para retry"       |
| `planner`    | Gera uma lista de etapas (Plan & Execute)   | "1. Buscar info; 2. Executar aÃ§Ã£o" |
| `executor`   | Realiza uma etapa do plano                  | "Buscar info sobre clima"          |
| `final`      | Marca o tÃ©rmino do grafo                    | Encerrar a execuÃ§Ã£o com resultado  |
ğŸ”¸ 2. **Edges (Arestas)**

Arestas definem as **transiÃ§Ãµes entre os nodes**. Podem ser:

- **Fixas**: vÃ£o sempre do Node A para o Node B.
    
- **Condicionais**: escolhem o prÃ³ximo node com base no estado.
    
- **Loop**: o node aponta para si mesmo (Ãºtil para ciclos como em ReAct ou AutoGPT).
    
- **Parallel branches**: mÃºltiplas transiÃ§Ãµes partindo de um node.
ğŸ“Œ Formas comuns de edges:

|Tipo de Edge|Como Ã© definido|Exemplo|
|---|---|---|
|`.add_edge("A", "B")`|TransiÃ§Ã£o simples|ApÃ³s o node A, vÃ¡ para B|
|`.add_conditional_edges("A", condition_fn)`|Escolha baseada em lÃ³gica|Se `state["done"] == True`, vÃ¡ para "final"|
|`.add_loop("A")`|Volta para o mesmo node|RepetiÃ§Ã£o enquanto necessÃ¡rio|
|`.add_branching_edges(...)`|ExecuÃ§Ã£o paralela ou mÃºltipla|Em multiagente ou pipelines|
ğŸ”¸ 3. **START e FINAL**

LangGraph define dois nodos especiais:

- `START`: ponto inicial da execuÃ§Ã£o.
    
- `FINAL`: ponto de parada quando a execuÃ§Ã£o termina.

```
graph = StateGraph(...)
graph.set_entry_point("start")
graph.add_edge("start", "llm_decision")
graph.add_edge("llm_decision", "tool_use")
graph.add_edge("tool_use", "FINAL")

```
