### üéØ Objetivo da Aula

- Compreender o que √© RAG e sua import√¢ncia.
    
- Aprender como construir um pipeline b√°sico de RAG.
    
- Explorar t√©cnicas avan√ßadas de otimiza√ß√£o e boas pr√°ticas para produ√ß√£o.

## üß© Parte 1: Fundamentos de RAG

### 1.1 O que √© RAG?

**Defini√ß√£o:**  
Retrieval-Augmented Generation √© uma t√©cnica que combina modelos de linguagem com mecanismos de recupera√ß√£o de documentos para responder perguntas com base em dados externos (contexto), fora do conhecimento treinado.

**Motiva√ß√£o:**

- Grandes LLMs esquecem fatos recentes ou espec√≠ficos.
    
- RAG permite incorporar contexto relevante dinamicamente.
    

**Arquitetura B√°sica:**

1. **Query ‚Üí Retriever ‚Üí Context**
    
2. **Context + Query ‚Üí LLM ‚Üí Resposta**
    

Use um diagrama simples para mostrar esse fluxo.

---
Racional:
### ‚ùìO que falta √†s LLMs?

Modelos de linguagem como GPT, Claude, Gemini e LLaMA s√£o impressionantes, mas t√™m **tr√™s limita√ß√µes fundamentais**:

1. **Mem√≥ria Est√°tica (Conhecimento Congelado)**
    
    - LLMs aprendem com os dados de seu treinamento.
        
    - Esses dados t√™m um corte temporal (ex: GPT-4 cortado em 2023-04).
        
    - N√£o conhecem fatos recentes ou informa√ß√µes espec√≠ficas de bases privadas.
        
2. **Limite de Conhecimento Espec√≠fico ou Profundo**
    
    - Mesmo com bilh√µes de par√¢metros, LLMs n√£o armazenam cada detalhe de cada √°rea do conhecimento.
        
    - Fatos muito espec√≠ficos, t√©cnicos ou confidenciais (como manuais internos, contratos ou bases cient√≠ficas) **n√£o s√£o acess√≠veis**.
        
3. **Falta de Personaliza√ß√£o**
    
    - LLMs s√£o generalistas.
        
    - Elas n√£o sabem nada sobre o seu dom√≠nio espec√≠fico, sua empresa, seu cliente ou seu caso de uso sem contexto externo.

## üìö O que √© RAG (Retrieval-Augmented Generation)?

**RAG** √© uma t√©cnica que combina **Language Models (LLMs)** com **Information Retrieval**, permitindo que o modelo gere respostas com base em dados externos, mesmo que esses dados n√£o estejam no seu treinamento original.

### 1.2 Componentes Principais

- **Retriever** (ex: FAISS, Weaviate, Elasticsearch, Chroma)
    
- **Embedding Models** (ex: `text-embedding-ada-002`, `all-MiniLM-L6-v2`)
    
- **Vector Store** (armazenamento e busca vetorial)
    
- **LLM** (ex: GPT-4, Mistral, LLaMA)

Racional:

## üß†O que s√£o **Embedding Models**?

Modelos de embedding s√£o modelos de linguagem treinados para **converter textos em vetores num√©ricos** de alta dimens√£o. Esses vetores preservam **rela√ß√µes sem√¢nticas**, ou seja, textos com significados semelhantes ter√£o vetores pr√≥ximos no espa√ßo vetorial.

Aqui est√£o os **melhores modelos de embedding** (at√© meados de 2025) para sistemas RAG, divididos entre solu√ß√µes propriet√°rias e open-source, com base em benchmarks (MTEB, BEIR) e artigos recentes:

---

## üöÄ Embeddings Propriet√°rios (Alta performance)

1. **Google Gemini embedding**
    
    - Aponta como _top performer_ em benchmarks de recupera√ß√£o [writingmate.ai+9arxiv.org+9arxiv.org+9](https://arxiv.org/abs/2505.13482?utm_source=chatgpt.com)[modal.com+2research.aimultiple.com+2techrepublic.com+2](https://research.aimultiple.com/retrieval-augmented-generation/?utm_source=chatgpt.com).
        
2. **Voyage-3-large**
    
    - ‚ÄúSurpresa no topo‚Äù da Astra DB, sendo o l√≠der em relev√¢ncia [unstructured.io+8datastax.com+8mongodb.com+8](https://www.datastax.com/blog/best-embedding-models-information-retrieval-2025?utm_source=chatgpt.com).
        
3. **OpenAI text-embedding-3-large**
    
    - Dimensionalidade configur√°vel, MRL, desempenho alto em MTEB [en.wikipedia.org+15mongodb.com+15vectorize.io+15](https://www.mongodb.com/developer/products/atlas/choose-embedding-model-rag/?utm_source=chatgpt.com).
        

---

## üåê Melhores modelos Open‚ÄëSource

1. **intfloat/e5-large-v2**
    
    - Muito eficiente e vers√°til para RAG [okareo.com+15modal.com+15writingmate.ai+15](https://modal.com/blog/embedding-models-article?utm_source=chatgpt.com).
        
2. **Salesforce/SFR-Embedding-2_R**
    
    - Forte em recupera√ß√£o sem√¢ntica [ukad-group.com+13modal.com+13mongodb.com+13](https://modal.com/blog/embedding-models-article?utm_source=chatgpt.com).
        
3. **intfloat/multilingual-e5-large-instruct**
    
    - Excelente para cen√°rios multil√≠ngues [modal.com](https://modal.com/blog/embedding-models-article?utm_source=chatgpt.com)[baseten.co](https://www.baseten.co/blog/the-best-open-source-embedding-models/?utm_source=chatgpt.com).
        
4. **BAAI bge-en-icl**
    
    - ‚ÄúMelhor modelo geral‚Äù open‚Äësource, usado como refer√™ncia [arxiv.org+2baseten.co+2modal.com+2](https://www.baseten.co/blog/the-best-open-source-embedding-models/?utm_source=chatgpt.com).
        
5. **Dewey long-context model**
    
    - Suporta janelas longas (at√© 128k tokens), √≥timo para documentos extensos [en.wikipedia.org+15arxiv.org+15arxiv.org+15](https://arxiv.org/abs/2503.20376?utm_source=chatgpt.com).
        

---

## üß† Modelos Especializados

- **MedEIR**
    
    - Embedding m√©dico, com contexto longo e precis√£o em textos cient√≠ficos .
        
- **E5 family (E5-base, E5-large)**
    
    - Bem testados em BEIR/MTEB, robustos para busca zero-shot [en.wikipedia.org+11arxiv.org+11okareo.com+11](https://arxiv.org/abs/2212.03533?utm_source=chatgpt.com).
        
- **OpenAI text-embedding-3-large**
    
    - Embedding configur√°vel (3072 dimens√µes), instru√ß√£o-tuned [arxiv.org+15mongodb.com+15datastax.com+15](https://www.mongodb.com/developer/products/atlas/choose-embedding-model-rag/?utm_source=chatgpt.com).

## üìö **Vector Store**

### O que √©:

O **Vector Store** √© o banco de dados onde ficam armazenados os vetores dos documentos (gerados por embeddings). Ele permite fazer buscas vetoriais de forma eficiente.

### Como funciona:

- Cada documento/chunk √© representado por um vetor.
    
- Quando uma query chega, o vetor dela √© comparado com todos os vetores no banco para encontrar os mais similares.
---
## üöÄ Parte 2: Uso Avan√ßado e Otimiza√ß√£o

### 2.1 Limita√ß√µes do RAG Padr√£o

- Recupera√ß√µes irrelevantes
    
- Contexto irrelevante ou muito extenso (Token Overflow)
    
- Alucina√ß√µes mesmo com contexto
    
- Custo e lat√™ncia em produ√ß√£o

### 2.2 Estrat√©gias de Otimiza√ß√£o

#### üîé Otimiza√ß√£o do Retrieval

- **Reranking com Cross-Encoder** (colBERT, Cohere Rerank)
    
- **Multivector Indexing**: tokenizar documentos em m√∫ltiplos chunks sem√¢nticos
    
- **Hybrid Search**: Combinar vetorial + BM25
    

#### üìè Otimiza√ß√£o do Contexto

- **Chunking sem√¢ntico**: usar t√≠tulos, subt√≥picos, heading-tags para corte inteligente
    
- **Maximizar conte√∫do por token √∫til**
    
- **Score Filtering** com limiares de similaridade
    

#### üß† Prompt Engineering

- **Injectar o contexto com delimita√ß√£o clara** (e.g. `### CONTEXTO`)
    
- **Instru√ß√µes para usar apenas informa√ß√µes do contexto**
    
- **Few-shot RAG**: exemplos de uso no contexto


### 2.3 Arquiteturas Avan√ßadas

- **Conversational RAG**: hist√≥rico mantido com mem√≥ria e re-query
    
- **RAG em Grafos de Conhecimento**: integra√ß√£o com bases estruturadas
    
- **RAG + Agent (Tool use)**: uso de ferramentas baseado em contexto retornado

### 2.4 M√©tricas de Avalia√ß√£o

- **Precision/Recall do Retrieval**
    
- **ROUGE, BLEU, BERTScore para gera√ß√£o**
    
- **Groundedness & Faithfulness**
    
- **Ragas (Retrieval-Augmented Generation Assessment Score)**

### 2.5 Casos de Uso no Mundo Real

- Chatbots jur√≠dicos, m√©dicos, financeiros
    
- Pesquisa em bases cient√≠ficas
    
- An√°lise de documentos corporativos
## üß© Arquiteturas Avan√ßadas de RAG

### 1. Retrieve‚Äëand‚ÄëRerank (Dois Est√°gios)

- **Fluxo**: busca r√°pida com bi‚Äëencoder ‚Üí reranking com cross‚Äëencoder ‚Üí LLM.
    
- **Pr√≥s**: alta precis√£o ao filtrar ru√≠do.
    
- **Contras**: maior lat√™ncia e complexidade operacional [arxiv.org+15skphd.medium.com+15medium.com+15](https://skphd.medium.com/different-rag-architectures-every-ai-professional-should-know-04f228e50fc3?utm_source=chatgpt.com).
    

---

### 2. Multimodal RAG

- **Descri√ß√£o**: incorpora dados n√£o textuais (imagens, v√≠deos, √°udios). Usa modelos como CLIP, Flamingo para embeddings.
    
- **Uso**: correto em manuais t√©cnicos, tutoria interativa.
    
- **Desafio**: requer alinhamento de embeddings e infraestrutura multimodal [skphd.medium.com+1github.com+1](https://skphd.medium.com/different-rag-architectures-every-ai-professional-should-know-04f228e50fc3?utm_source=chatgpt.com).
    

---

### 3. Graph‚Äëbased RAG

- **Descri√ß√£o**: documentos s√£o n√≥s em um grafo; s√£o realizadas buscas sem√¢nticas + travessia no grafo.
    
- **Vantagem**: excelente para racioc√≠nio multi-hop e rela√ß√µes estruturadas entre documentos.
    
- **Exemplo**: PankRAG resolve sub-perguntas hierarquicamente, reranking dependente de rela√ß√µes [skphd.medium.com](https://skphd.medium.com/different-rag-architectures-every-ai-professional-should-know-04f228e50fc3?utm_source=chatgpt.com)[arxiv.org+1skphd.medium.com+1](https://arxiv.org/abs/2506.11106?utm_source=chatgpt.com).
    
- **Outra abordagem**: GeAR faz expans√£o via grafo e agentes para recupera√ß√£o multi-hop [github.com+15arxiv.org+15arxiv.org+15](https://arxiv.org/html/2501.09136v1?utm_source=chatgpt.com).
    

---

### 4. Hybrid RAG (Vetorial + Grafo)

- **Fluxo**: busca vetorial + travessia de grafo + mescla dos resultados.
    
- **Benef√≠cios**: combina profundidade sem√¢ntica e estrutura relacional.
    
- **Caso real**: projeto com FAISS + BM25 + Knowledge Graph + HyDe + reranking via Cohere [reddit.com+11reddit.com+11reddit.com+11](https://www.reddit.com/r/Rag/comments/1fu9u5r?utm_source=chatgpt.com).
    

---

### 5. Agentic ou Multi‚ÄëAgent RAG

- **Router Agent**: decide a melhor estrat√©gia de recupera√ß√£o ou rota entre √≠ndices, vetores, grafo ou APIs [skphd.medium.com](https://skphd.medium.com/different-rag-architectures-every-ai-professional-should-know-04f228e50fc3?utm_source=chatgpt.com).
    
- **Hierarchical Multi‚ÄëAgent RAG (HM‚ÄëRAG)**: decomposi√ß√£o de queries, agentes especializados por modalidade e valida√ß√£o via consenso [arxiv.org+15arxiv.org+15skphd.medium.com+15](https://arxiv.org/abs/2504.12330?utm_source=chatgpt.com).
    
- **Multi-Agent RAG Customer Support**: roteamento por auxiliar especializado, com gerenciamento de estado e ferramentas de verifica√ß√£o [github.com](https://github.com/ro-anderson/multi-agent-rag-customer-support?utm_source=chatgpt.com).
    

Trechos da comunidade:

> ‚ÄúRetrieval Becomes Agentic: ... the agent (Router) uses different retrieval tools ‚Ä¶ decides which tool to invoke based on the context.‚Äù [markovate.com+9reddit.com+9skphd.medium.com+9](https://www.reddit.com/r/LangChain/comments/1hzxdgn?utm_source=chatgpt.com)

---

### 6. Query Planning / Adaptive RAG

- **Adaptive RAG**: analisa a complexidade da query e decide dinamicamente se executa um ou m√∫ltiplos passos de RAG ou at√© um caminho sem retrieval [analyticsvidhya.com](https://www.analyticsvidhya.com/blog/2025/01/agentic-rag-system-architectures/?utm_source=chatgpt.com).
    

---

### 7. Graph RAG + Tool Fusion

- **Objetivo**: usar grafo n√£o s√≥ para documentos, mas para sele√ß√£o de ferramentas em agentes (ex: geolocaliza√ß√£o, banco SQL) [arxiv.org](https://arxiv.org/html/2502.07223v1?utm_source=chatgpt.com).